import os
import sys
import json
import asyncio
root_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(root_dir)

import gemini
import news_crawler
import infrastructure.redis_manager


async def main(category: str):
    # 1. å»ºç«‹å¯¦ä¾‹
    DB = news_crawler.NewsDB()
    gemini_client = gemini.gemini_client()
    redis_mgr = infrastructure.redis_manager.RedisManager()

    try:
        # 2. é–‹å•Ÿæ‰€æœ‰é€£ç·šæ±  (ç¢ºä¿é€™äº›æ–¹æ³•å…§éƒ¨æœ‰ä½¿ç”¨ await)
        await DB.pool_init()
        await redis_mgr.init_pool()
        print("ğŸš€ æ‰€æœ‰é€£ç·šæ± åˆå§‹åŒ–æˆåŠŸ")

        # 3. åŸ·è¡Œæ‰¹æ¬¡ä»»å‹™
        # é€™è£¡ä¸éœ€è¦ asyncio.runï¼Œå› ç‚ºæˆ‘å€‘å·²ç¶“åœ¨ main() è£¡é¢äº†
        raw_summaries = await news_crawler.batch_generate_sg_summaries(
            category=category, 
            DB_instance=DB, 
            gemini_instance=gemini_client, 
            redis_manager_instance=redis_mgr
        )
        
        
        if raw_summaries:
            all_summaries = []
            print("âœ… æˆåŠŸç”Ÿæˆæ‘˜è¦")
            print(f"ç¯„ä¾‹çµæœ: {raw_summaries[0]}")
            print("\n----------------------------------------\n")
            for item in raw_summaries:
                summaries = json.loads(item)
                all_summaries.extend(summaries)
            print(type(all_summaries))

        news_summary_list = []
        for news in all_summaries:
            points = news.get("points", "")
            points_str = ""
            for i, point in enumerate(points):
                points_str += f"{i+1}. {point}\n"

            news_tuple = (news.get("news_id", ""), points_str, category)
            news_summary_list.append(news_tuple)
        await DB.insert_news_summary(news_summary_list=news_summary_list)
        print("æ‘˜è¦æˆåŠŸå­˜å…¥è³‡æ–™åº«")




    except Exception as e:
        print(f"âŒ åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")

    finally:
        # 4. ç„¡è«–æˆåŠŸæˆ–å¤±æ•—ï¼Œéƒ½å„ªé›…é—œé–‰é€£ç·š (é€™å°±æ˜¯å°ˆæ¥­çš„æ¸…ç†)
        print("ğŸ’¤ æ­£åœ¨é—œé–‰é€£ç·š...")
        await DB.pool_close()
        await redis_mgr.close()
        # å¦‚æœ gemini ä¹Ÿæœ‰ close æ–¹æ³•è«‹åŠ ä¸Š
        if hasattr(gemini_client, 'close'):
            await gemini_client.close()


if __name__ == "__main__":
    asyncio.run(main("å…©å²¸"))

"""
{'news_id': '9306002', 
'title': 'æ–°èˆˆå¸‚å ´ä¸Šå‘¨æŒçºŒå¸å¼•è³‡é‡‘æµå…¥ å°è‚¡æœ€å¸é‡‘', 
'points': ['æ–°èˆˆå¸‚å ´ETFé€£çºŒ15é€±å¸å¼•è³‡é‡‘ï¼Œç´¯è¨ˆæµå…¥428å„„ç¾å…ƒï¼›ä¸Šé€±ï¼ˆæˆªè‡³1æœˆ30æ—¥ï¼‰å†å¸é‡‘65å„„ç¾å…ƒï¼Œç„¡åœ‹å®¶è³‡é‡‘æµå‡ºã€‚', 
            'å°ç£è³‡ç”¢ä¸Šé€±å¸é‡‘13.93å„„ç¾å…ƒç¨±å† æ–°èˆˆå¸‚å ´ï¼Œå…¨æ•¸æµå…¥å°è‚¡ETFï¼Œå—éŸ“èˆ‡ä¸­æ¸¯åˆ†å±…äºŒã€ä¸‰åã€‚', 
            'ä»Šå¹´ä¾†æ–°èˆˆå¸‚å ´å·²å¸é‡‘249å„„ç¾å…ƒï¼Œåæ˜ AIé¡è‚¡æš´æ¼²ã€ç¾åœ‹æ”¿ç­–ä¸ç¢ºå®šæ€§åŠç¾å…ƒç–²è»Ÿï¼Œä¿ƒä½¿æŠ•è³‡äººèª¿æ•´åœ°ç†æ›éšªã€‚', 
            'ç‘éŠ€é æœŸ2026å¹´æŠ•è³‡ä¸»è»¸ç‚ºåˆ†æ•£æŠ•è³‡ï¼Œå°‡ææŒ¯æ–°èˆˆå¸‚å ´è¡¨ç¾ï¼Œç‰¹åˆ¥æ˜¯éå»é…ç½®æ¯”ç‡åä½çš„åœ°å€ã€‚']
            }
"""